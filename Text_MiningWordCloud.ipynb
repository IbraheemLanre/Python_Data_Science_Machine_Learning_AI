{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()\n",
    "pip install WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/community.txt', 'r') as f:\n",
    "    community = f.read()\n",
    "all_snippets = community\n",
    "\n",
    "text = ' '\n",
    "for snippet in all_snippets:\n",
    "    text+=snippet[0]\n",
    "\n",
    "\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "wordcloud = WordCloud(stopwords=STOPWORDS,background_color='white',width=3000,height=3000).generate(text)\n",
    "\n",
    "\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using PlainTextCorpusReader to read the directories. It reads all matching giles in a directory and saves them by file-ids\n",
    "\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "community_root = \"data/community\"\n",
    "le_monde_root = \"data/le_monde\"\n",
    "community_files = \"community.*\"\n",
    "le_monde_files = \"le_monde.*\"\n",
    "heights_root = \"data/heights\"\n",
    "heights_files = \"heights.*\"\n",
    "amigos_root = \"data/amigos\"\n",
    "amigos_files = \"amigos.*\"\n",
    "community_data = PlaintextCorpusReader(community_root,community_files)\n",
    "le_monde_data = PlaintextCorpusReader(le_monde_root,le_monde_files)\n",
    "heights_data = PlaintextCorpusReader(heights_root,heights_files)\n",
    "amigos_data = PlaintextCorpusReader(amigos_root,amigos_files)\n",
    "\n",
    "# Simple Analysis: Complexity\n",
    "# Comparison details of local resturants. \n",
    "# Counting the number of sentences and words in the data\n",
    "text = le_monde_data.raw()\n",
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "sentences = nltk.Text(sent_tokenize(text))\n",
    "print(len(sentences))\n",
    "words = nltk.Text(word_tokenize(text))\n",
    "print(len(words))\n",
    "\n",
    "# counting the number of characters and getting the average length of a word\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_complexity(text):\n",
    "    num_chars = len(text)\n",
    "    num_words = len(word_tokenize(text))\n",
    "    num_sents = len(sent_tokenize(text))\n",
    "    vocab = {x.lower() for x in word_tokenize(text)}\n",
    "    return len(vocab), int(num_chars/num_words), int(num_words/num_sents), len(vocab)/num_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
