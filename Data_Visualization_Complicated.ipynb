{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_311_data(table):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    #Add the fix_zip function\n",
    "    def fix_zip(input_zip):\n",
    "        try:\n",
    "            input_zip = int(float(input_zip))\n",
    "        except:\n",
    "            try:\n",
    "                input_zip = int(input_zip.split('-')[0])\n",
    "            except:\n",
    "                return np.NaN\n",
    "        if input_zip < 10000 or input_zip > 19999:\n",
    "            return np.NaN\n",
    "        return str(input_zip)\n",
    "    \n",
    "    #Read the file\n",
    "    df = pd.read_csv(table,index_col='Unique Key')\n",
    "    \n",
    "    #fix the zip\n",
    "    df['Incident Zip'] = df['Incident Zip'].apply(fix_zip)\n",
    "    \n",
    "    #drop all rows that have any nans in them (note the easier syntax!)\n",
    "    \n",
    "    df = df.dropna(how='any')\n",
    "    \n",
    "    #get rid of unspecified boroughs\n",
    "    df = df[df['Borough'] != 'Unspecified']\n",
    "    \n",
    "    #Convert times to datetime and create a processing time column\n",
    "    \n",
    "    import datetime\n",
    "    df['Created Date'] = df['Created Date'].apply(lambda x:datetime.datetime.strptime(x,'%m/%d/%Y %I:%M:%S %p'))\n",
    "    df['Closed Date'] = df['Closed Date'].apply(lambda x:datetime.datetime.strptime(x,'%m/%d/%Y %I:%M:%S %p'))\n",
    "    df['processing_time'] =  df['Closed Date'] - df['Created Date']\n",
    "    \n",
    "    #Finally, get rid of negative processing times and return the final data frame\n",
    "    \n",
    "    df = df[df['processing_time']>=datetime.timedelta(0,0,0)]\n",
    "    \n",
    "    return df\n",
    "df = read_311_data('input_data')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = 'input_data'\n",
    "data = read_311_data(table)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gmplot --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drawing a heatmap that helps see the relative concentration of complaints using lats and lons\n",
    "    # Set up the map\n",
    "    # GoogleMapPlotter(center_lat, center_lon, zoom)\n",
    "    # from_geocode(location_string,zoom)\n",
    "\n",
    "import gmplot\n",
    "\n",
    "#Two ways to centre a map\n",
    "\n",
    "gmap = gmplot.GoogleMapPlotter(40.7128, -74.0059, 8)\n",
    "\n",
    "# OR\n",
    "\n",
    "#gmap = gmplot.GoogleMapPlotter.from_geocode(\"New York\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we generate the heatmap passing the two data series (latitude and longitude) to the function\n",
    "%matplotlib inlin\n",
    "gmap.heatmap(data['Latitude'], data['Longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the heatmanp to an html file that be viewed, printed or include in another html page\n",
    "%matplotlib inline\n",
    "gmap.draw('incidents.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Groupby\n",
    "# Incidents by Agency\n",
    "agency_group = data.groupby('Agency')\n",
    "agency_group.size().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining two groups into a singel graph\n",
    "agency_borough = data.groupby(['Agency', 'Borough'])\n",
    "agency_borough.size().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unstacking the groups so as to get borough by agency\n",
    "agency_borough.size().unstack().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increasing the image size and adding a title\n",
    "agency_borough = data.groupby(['Agency', 'Borough'])\n",
    "agency_borough.size().unstack().plot(kind = 'bar', title = 'Incidents in each Agency by Borough', figsize = (15, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEASONAL ANALYSIS\n",
    "# Incidents by time, Since we know the creation date of each incident, we can bild a bar graph of number of incidents by month\n",
    "# First create a new date field yyyymm\n",
    "import datetime\n",
    "data['yyyymm'] = data['Created Date'].apply(lambda x: datetime.datetime.strftime(x, '%Y%m'))\n",
    "data['yyyymm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_agency = data.groupby(['yyyymm', 'Agency'])\n",
    "data_agency.size().unstack().plot(kind = 'bar', figsize = (12, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examining Agencies. We'll look at the frequency by agency and report the top 5 values\n",
    "data.groupby('Agency').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('Agency').size().sort_values(ascending=False).plot(kind = 'bar', figsize = (20, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drilling down into complaints by Agency by borough\n",
    "agency_borough = data.groupby(['Agency', 'Borough']).size().unstack()\n",
    "agency_borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can create 'top 5 Agency' subplots. Subplots for each borough\n",
    "# Arranging the subplots in two rows and three columns. Since there are 5 borough, one plot will be blank\n",
    "\n",
    "COL_NUM = 2\n",
    "ROW_NUM = 3\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(ROW_NUM, COL_NUM, figsize = (12, 12))\n",
    "\n",
    "for i, (label, col) in enumerate(agency_borough.iteritems()):\n",
    "    ax = axes[int(i/COL_NUM), i%COL_NUM]\n",
    "    col = col.sort_values(ascending = False)[:5]\n",
    "    col.plot( kind = 'barh', ax = ax)\n",
    "    ax.set_title(label)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing simple statistics on processing time\n",
    "\n",
    "grouped = data[['processing_time', 'Borough']].groupby('Borough')\n",
    "grouped.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the timedelta processing_time into floats for calculation purposes\n",
    "data['float_time'] = data['processing_time'].apply(lambda x: x/np.timedelta64(1, 'D'))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now computing stats is easy using from the above code\n",
    "grouped = data[['float_time', 'Agency']].groupby('Agency')\n",
    "grouped.mean().sort_values('float_time', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['float_time'].hist(bins = 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
